{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9847574a-8310-431d-a8b2-9a3a960d2ced",
   "metadata": {},
   "source": [
    "## Inference Test on Test Data Set: LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca7ac9-8f38-479f-8970-0031db246ce9",
   "metadata": {},
   "source": [
    "### Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca343e8-6fa3-4479-8bdc-163eff301fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "794cc6e7-c24f-4f01-965c-661eb3067152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5fac17f-a407-4d19-8ce3-cedbfeeb7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "defc49db-9a48-406a-8475-f39dc7cb45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "batch_size_train = 50\n",
    "max_len = 28\n",
    "vocab_size = 5001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042638b3-5c84-4ec5-8dca-62702c01e325",
   "metadata": {},
   "source": [
    "**Selected hyperparameters**  \n",
    "Learning rate: 0.001  \n",
    "Hidden dim: 32  \n",
    "Number of LSTM layers: 2  \n",
    "Epoch number: 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "464cbe86-45fd-4ed0-b23b-72814cddcae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de6344f-b37f-4529-ad84-32aa4ece696e",
   "metadata": {},
   "source": [
    "### Import the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a158739e-eb92-419d-9eb9-9fa5ef4d6bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_test = pd.read_csv('tweets_5000/test/X_test.csv')\n",
    "df_y_test = pd.read_csv('tweets_5000/test/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d8e05f1-e2ac-43dc-bcc8-441115d88dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe  to numpy array\n",
    "X_test = df_X_test.to_numpy().squeeze()\n",
    "y_test = df_y_test.to_numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b6f8722-aac9-48d6-833a-b26f6cff9c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_list = pd.read_csv('tweets_5000/vocab/word_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa9588ec-2569-4060-a2f6-1f4db6cbce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = df_word_list.iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dac27298-14cb-413d-8311-262ed343436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_count = Counter(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "490dfd4f-05d7-4940-aab4-4aab1fdd8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(vocab_count,key=vocab_count.get,reverse=True)[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ffa08682-9031-4319-a07f-c5684283d6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12495"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words = sorted(vocab_count.values(), reverse=True)\n",
    "len(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c42c81d8-4b88-432c-ae3f-691e69a87b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5469"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words with more than one occurrence\n",
    "words_more_than_1 = list(filter(lambda x: x > 1, count_words))\n",
    "len(words_more_than_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b9d2133-602d-4b17-b4c7-b7f57ee88cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_less_than_50 = list(filter(lambda x: x < 50, count_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a08b66e-dd1f-4fad-916f-124202743685",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_all = sorted(vocab_count,key=vocab_count.get,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9884171c-5d76-43a6-935f-6012df42d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {w:i+1 for i,w in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d47c6b63-8a7e-4920-907a-db193349f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train_padded = pd.read_csv('tweets_5000/train/x_train_padded.csv')\n",
    "df_x_valid_padded = pd.read_csv('tweets_5000/valid/x_valid_padded.csv')\n",
    "df_X_test = pd.read_csv('tweets_5000/test/X_test.csv')\n",
    "df_y_test = pd.read_csv('tweets_5000/test/y_test.csv')\n",
    "df_y_train = pd.read_csv('tweets_5000/train/y_train.csv')\n",
    "df_y_valid = pd.read_csv('tweets_5000/valid/y_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c852d2a-3d6d-42d8-8f98-c22d0828b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe  to numpy array\n",
    "x_train_padded = df_x_train_padded.to_numpy()\n",
    "x_valid_padded = df_x_valid_padded.to_numpy()\n",
    "X_test = df_X_test.to_numpy().squeeze()\n",
    "y_test = df_y_test.to_numpy().squeeze()\n",
    "y_train = df_y_train.to_numpy().squeeze()\n",
    "y_valid = df_y_valid.to_numpy().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec7a584-6907-4791-ac24-642764f88141",
   "metadata": {},
   "source": [
    "### Create final dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90c2603a-0225-4257-836c-8035ca531033",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_padded = np.array(x_train_padded)\n",
    "x_valid_padded = np.array(x_valid_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b1dd87a-596f-4e64-b26d-c9289ecc2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(x_train_padded), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(x_valid_padded), torch.from_numpy(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "706b77a7-b15c-4cd9-8603-7bca6009507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dataloader with shuffle on\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b2e1113-fea1-4eb6-a23c-f22bb0464437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([50, 28])\n",
      "Labels batch shape: torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "# Display tweet and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3176a049-4588-4cfb-9cf2-fac0eff15599",
   "metadata": {},
   "source": [
    "### Define LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "162877a3-39c0-480c-94be-16ae59b54ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetLSTM(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout, num_layers) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # The embedding layer takes the vocab size and the embeddings size as input\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        # The LSTM layer takes in the the embedding size and the hidden vector size.\n",
    "        #self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim,\n",
    "                    num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Use dropout before the final layer to improve with regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # The fully-connected layer takes in the hidden dim of the LSTM and\n",
    "        #  outputs a 2x1 vector of the class scores.\n",
    "        self.fc = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        The forward method takes in the input and the previous hidden state \n",
    "        \"\"\"\n",
    "\n",
    "        # The input is transformed to embeddings by passing it to the embedding layer\n",
    "        embs = self.embedding(x)\n",
    "\n",
    "        # The embedded inputs are fed to the LSTM alongside the previous hidden state\n",
    "        out, hidden = self.lstm(embs, hidden)\n",
    "\n",
    "        # Dropout is applied to the output and fed to the FC layer\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # We extract the scores for the final hidden state since it is the one that matters.\n",
    "        out = out[:, -1]\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_dim), \n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf697d-f40d-46e0-9bc2-7645dd6a1ba0",
   "metadata": {},
   "source": [
    "### Initialize TweetLSTM class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68f32a80-5db4-4e34-9b85-c0185166c97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TweetLSTM(\n",
      "  (embedding): Embedding(5001, 64, padding_idx=0)\n",
      "  (lstm): LSTM(64, 32, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 64\n",
    "hidden_dim = 32\n",
    "dropout = 0.2\n",
    "num_layers = 2\n",
    "\n",
    "#model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5)\n",
    "model = TweetLSTM(vocab_size, embedding_dim, hidden_dim, dropout, num_layers)\n",
    "\n",
    "#moving to gpu\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a255d8ef-d56f-45e7-963a-85fb0415c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f23a5fd-582c-4d75-ba49-dff981a322eb",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b4c06d1-a8fd-439e-b5ae-cf01a35864fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to predict accuracy\n",
    "def acc(out,label):\n",
    "    _, pred = torch.max(out, 1)\n",
    "    return torch.sum(pred == label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "565c5f49-2d75-4521-bf7d-7aa211b80b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss : 0.6899784299043509\n",
      "train_accuracy : 52.41843032836914\n",
      "============================================================\n",
      "Epoch 2\n",
      "train_loss : 0.6305122570349619\n",
      "train_accuracy : 65.64299774169922\n",
      "============================================================\n",
      "Epoch 3\n",
      "train_loss : 0.5491094804153993\n",
      "train_accuracy : 72.4568099975586\n",
      "============================================================\n",
      "Epoch 4\n",
      "train_loss : 0.4506462557384601\n",
      "train_accuracy : 79.9040298461914\n",
      "============================================================\n",
      "Epoch 5\n",
      "train_loss : 0.38860702901505506\n",
      "train_accuracy : 83.01343536376953\n",
      "============================================================\n",
      "Epoch 6\n",
      "train_loss : 0.3380555599354781\n",
      "train_accuracy : 85.8541259765625\n",
      "============================================================\n",
      "Epoch 7\n",
      "train_loss : 0.2925582710080422\n",
      "train_accuracy : 89.0403060913086\n",
      "============================================================\n",
      "Epoch 8\n",
      "train_loss : 0.24769506904368216\n",
      "train_accuracy : 91.0556640625\n",
      "============================================================\n",
      "Epoch 9\n",
      "train_loss : 0.22181315863361725\n",
      "train_accuracy : 92.51439666748047\n",
      "============================================================\n",
      "Epoch 10\n",
      "train_loss : 0.19558816087933686\n",
      "train_accuracy : 93.7427978515625\n",
      "============================================================\n",
      "Epoch 11\n",
      "train_loss : 0.18479679739819124\n",
      "train_accuracy : 94.22264862060547\n",
      "============================================================\n",
      "Epoch 12\n",
      "train_loss : 0.16016311422348595\n",
      "train_accuracy : 95.16314697265625\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "model = TweetLSTM(vocab_size, embedding_dim, hidden_dim, dropout, num_layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "clip = 5\n",
    "epochs = 12\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_preds = []\n",
    "    epoch_labels = []\n",
    "    train_losses = []\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    # initialize hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "    for inputs, labels in train_dataloader:\n",
    "       \n",
    "        inputs, labels = inputs.to(device), labels.to(device)  \n",
    "        # Get a new copy of initialized h, leaving the original h unchanged.\n",
    "        h = tuple([x.data for x in h])\n",
    "       \n",
    "        model.zero_grad()\n",
    "        output, h = model(inputs, h)\n",
    "        # calculate the loss and perform backpropagation\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "        # calculating accuracy\n",
    "        accuracy = acc(output,labels)\n",
    "        train_acc += accuracy\n",
    "        # clip helps prevent the exploding gradient problem in LSTM.\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()               \n",
    "           \n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_train_acc = train_acc/len(train_dataloader.dataset)\n",
    "\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    print(f'train_loss : {epoch_train_loss}')\n",
    "    print(f'train_accuracy : {epoch_train_acc*100}')\n",
    "    print(30 * '==')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2cde0b-4e8d-43c4-b72f-accdb621c547",
   "metadata": {},
   "source": [
    "### Save and reload the trained params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1b8b90a9-2f4a-493b-88ad-1d019e2ab2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab581f18-21e7-4634-ab19-95458c77a93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yq/btccqhv52_3c37ngrplz3ct80000gn/T/ipykernel_31612/80206951.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('state_dict.pt')\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('state_dict.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b3c5927a-2079-45e4-9f8c-9e31e4c07423",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TweetLSTM(vocab_size, embedding_dim, hidden_dim, dropout, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "649c1b16-0ee5-4cc9-9b97-73c5dd432806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved parameters into the model\n",
    "model.load_state_dict(state_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "43f1ea61-6f0e-4903-85e9-03d28ac19da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TweetLSTM(\n",
       "  (embedding): Embedding(5001, 64, padding_idx=0)\n",
       "  (lstm): LSTM(64, 32, num_layers=2, batch_first=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4e75f-9df3-47b6-9530-5a8e66b7d2d8",
   "metadata": {},
   "source": [
    "### Inference / Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b65c64a-18c1-4577-ad2c-48fd1fdbadd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the argument \"tokenized_tweet\" is a tokenized tweet without stop words.\n",
    "def padded_vector(tokenized_tweet, vocab_dict, max_len):\n",
    "    int_tweet = []\n",
    "    for word in tokenized_tweet:\n",
    "        if word in vocab_dict:\n",
    "            int_tweet.append(vocab_dict[word])  \n",
    "\n",
    "    padded_vector = int_tweet + [0] * max(0, max_len - len(int_tweet))\n",
    "    return padded_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73c74b5b-c501-4d81-aa2b-e26dcf05fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the argument tweet is the raw text data.\n",
    "def create_padded_tokens(tweet):\n",
    "    tweet = re.sub(r'[,!?;-]', '.', tweet) #  Punctuations are replaced by \".\"\n",
    "    #tweet_lowered = tweet.lower()\n",
    "    tokenized_tweet = nltk.word_tokenize(tweet) \n",
    "    #  Lower case and drop non-alphabetical tokens\n",
    "    tokenized_tweet = [ch.lower() for ch in tokenized_tweet if ch.isalpha() or ch == '.']  \n",
    "    english_stopwords = stopwords.words('english')\n",
    "    tokens_wo_stopwords = [t for t in tokenized_tweet if t not in english_stopwords]\n",
    "    tokens_padded = np.array(padded_vector(tokens_wo_stopwords, vocab_dict, max_len))\n",
    "    tokens_padded = np.expand_dims(tokens_padded, axis=0) # To change 2-d array to 3-d to use in model(inputs, h).\n",
    "\n",
    "    return tokens_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5135fcf9-b6a3-4a9a-a1d4-21a889213175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict one tweet at a time. (batch_size is set at 1.)\n",
    "def predict_tweet(tokens_padded):\n",
    "    pad =  torch.from_numpy(tokens_padded) \n",
    "    inputs = pad.to(device)\n",
    "    batch_size = 1\n",
    "    h = model.init_hidden(batch_size)\n",
    "    h = tuple([each.data for each in h])\n",
    "    output, h = model(inputs, h)\n",
    "    #print(output[0])\n",
    "    out = nn.Sigmoid()(output[0][1])\n",
    "    return(out.item())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "25c60220-dbc9-441d-bf0a-6e54ad826940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seismic NA #Sismo DETECTADO #JapÌ_n [Report 3] 01:02:17 Okinawa Island region M3.8 Depth 10km Maximum seismic intensity 3 JST #??\n",
      "======================================================================\n",
      "Actual target is  : 1\n",
      "======================================================================\n",
      "Predicted sentiment is Disaster with a probability of 0.9275115132331848\n"
     ]
    }
   ],
   "source": [
    "index = 525\n",
    "print(X_test[index])\n",
    "print('='*70)\n",
    "print(f'Actual target is  : {y_test[index]}')\n",
    "print('='*70)\n",
    "tokens_padded = create_padded_tokens(X_test[index])\n",
    "prob = predict_tweet(tokens_padded)\n",
    "status = \"Disaster\" if prob > 0.5 else \"Non-disaster\"\n",
    "prob = (1 - prob) if status == \"Non-disaster\" else prob\n",
    "print(f'Predicted sentiment is {status} with a probability of {prob}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe17d16-c0c7-44fd-8198-e9df07eef3db",
   "metadata": {},
   "source": [
    "### Test accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "addea64e-37bc-44d7-85b5-0f48cf84eab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1737"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0ff541d2-edbc-45c4-8928-de8e72511a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7697)\n"
     ]
    }
   ],
   "source": [
    "#batch_size_test = 1\n",
    "all_batches_acc = []\n",
    "for idx in range(len(X_test)):\n",
    "    batch_acc = []\n",
    "\n",
    "    tweet = X_test[idx]\n",
    "    tokens_padded = create_padded_tokens(tweet)\n",
    "    prob = torch.tensor(predict_tweet(tokens_padded))\n",
    "    pred = torch.round(prob)\n",
    "    target = y_test[idx]\n",
    "    batch_acc.append(pred == target)\n",
    "        \n",
    "    all_batches_acc.extend(batch_acc) \n",
    "\n",
    "accuracy = sum(all_batches_acc)/len(X_test)\n",
    "print(accuracy)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186f2cab-0ccf-42d0-9354-8c8d521fe035",
   "metadata": {},
   "source": [
    "### Precision, Recall, and F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "daaac723-90cc-47a1-987c-5c5c94cc5f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_pred, y_true):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()    \n",
    "    precision = round(tp / (tp + fp), 3)\n",
    "    recall = round(tp / (tp + fn), 3)\n",
    "    f1_score = round(2 * precision * recall / (precision + recall), 3)\n",
    "\n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dfc3cf82-7bd1-4ba1-b6c4-8f19e79cf7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "targets = []\n",
    "for idx in range(len(X_test)):\n",
    "    batch_acc = []\n",
    "\n",
    "    tweet = X_test[idx]\n",
    "    tokens_padded = create_padded_tokens(tweet)\n",
    "    prob = torch.tensor(predict_tweet(tokens_padded))\n",
    "    pred = torch.round(prob)\n",
    "    target = y_test[idx]\n",
    "\n",
    "    preds.append(int(pred.item()))\n",
    "    targets.append(target.item())\n",
    "\n",
    "precision, recall, f1_score = calc_metrics(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "da25036d-f893-44a8-a4b7-30d344c6de8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  77.0%\n",
      "Precision:  75.6%\n",
      "Recall:  79.9%\n",
      "F1 score:  77.7%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy*100: .1f}%\\nPrecision: {precision*100: .1f}%\\nRecall: {recall*100: .1f}%\\nF1 score: {f1_score*100: .1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b71aa-bccd-43e1-a47c-433c29bcba6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skorch-310",
   "language": "python",
   "name": "skorch-310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
